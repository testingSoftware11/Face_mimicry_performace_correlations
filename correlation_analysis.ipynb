{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rkuqmp0ICxl5"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "import pandas as pd\n",
        "import json\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summrize all metadata files"
      ],
      "metadata": {
        "id": "R2ycdfKKDChk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_metadata(metadata_path):\n",
        "    rows = []\n",
        "    for file in os.listdir(metadata_path):\n",
        "        if file.endswith(\".json\"):\n",
        "            with open(os.path.join(metadata_path, file), \"r\") as f:\n",
        "                data = json.load(f)\n",
        "            starts = [datetime.fromisoformat(t.replace(\"Z\", \"\")) for t in data[\"calibration_started\"]]\n",
        "            ends = [datetime.fromisoformat(t.replace(\"Z\", \"\")) for t in data[\"back_from_calibration\"]]\n",
        "            durations = [(e - s).total_seconds() for s, e in zip(starts, ends)]\n",
        "            total_time = sum(durations)\n",
        "            mean_time = total_time / len(durations) if durations else 0\n",
        "            rows.append({\n",
        "                \"user_id\": data[\"user_id\"],\n",
        "                \"video_id\": data[\"video_id\"],\n",
        "                \"count_calibrations\": len(durations),\n",
        "                \"total_calibration_time\": total_time,\n",
        "                \"mean_calibration_time\": mean_time\n",
        "            })\n",
        "    return pd.DataFrame(rows)"
      ],
      "metadata": {
        "id": "BFzOO7z6DFZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload metadata JSON files"
      ],
      "metadata": {
        "id": "M54HSwgfDHnD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Please upload ALL metadata JSON files (one or more):\")\n",
        "uploaded_metadata = files.upload()\n",
        "\n",
        "metadata_dir = \"uploaded_metadata\"\n",
        "os.makedirs(metadata_dir, exist_ok=True)\n",
        "for filename, content in uploaded_metadata.items():\n",
        "    with open(os.path.join(metadata_dir, filename), \"wb\") as f:\n",
        "        f.write(content)\n",
        "\n",
        "metadata_summary = summarize_metadata(metadata_dir)"
      ],
      "metadata": {
        "id": "6vs-S6syDLJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload performance CSV file"
      ],
      "metadata": {
        "id": "bRnZuj7HHXyc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nPlease upload the performance CSV file:\")\n",
        "uploaded_performance = files.upload()\n",
        "\n",
        "performance_filename = list(uploaded_performance.keys())[0]\n",
        "performance_path = os.path.join(\".\", performance_filename)\n",
        "with open(performance_path, \"wb\") as f:\n",
        "    f.write(uploaded_performance[performance_filename])\n",
        "\n",
        "performance = pd.read_csv(performance_path)"
      ],
      "metadata": {
        "id": "oWPxGfcuHZY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reshape performance data"
      ],
      "metadata": {
        "id": "u7L1-cR-Ha_0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "melted = performance.melt(\n",
        "    id_vars=[\"participant\"],\n",
        "    value_vars=[\"Merav1_mean\", \"Merav2_mean\", \"Merav3_mean\"],\n",
        "    var_name=\"video_id\",\n",
        "    value_name=\"performance_score\"\n",
        ")\n",
        "melted[\"video_id\"] = melted[\"video_id\"].str.replace(\"_mean\", \"\")\n",
        "melted.rename(columns={\"participant\": \"user_id\"}, inplace=True)\n"
      ],
      "metadata": {
        "id": "e5koeNwGHdbn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Merge performance + metadata"
      ],
      "metadata": {
        "id": "JlzN01ocHgNy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merged = melted.merge(metadata_summary, on=[\"user_id\", \"video_id\"], how=\"left\")\n"
      ],
      "metadata": {
        "id": "SZDc03CHHhoa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Correlation analysis"
      ],
      "metadata": {
        "id": "6ewLLMjPHiz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corrs = merged[[\"performance_score\", \"count_calibrations\", \"total_calibration_time\", \"mean_calibration_time\"]].corr(method=\"pearson\")\n",
        "print(\"\\nCorrelation matrix:\\n\", corrs)\n"
      ],
      "metadata": {
        "id": "JLvG8LqBHlA4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Save and visualize"
      ],
      "metadata": {
        "id": "nWS8slKIHmgv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merged.to_csv(\"correlation_results.csv\", index=False)\n",
        "print(\"\\nSaved merged results as 'correlation_results.csv'. You can download it below:\")\n",
        "\n",
        "files.download(\"correlation_results.csv\")\n",
        "\n",
        "# Get the correlation value\n",
        "corr_value = corrs.loc[\"total_calibration_time\", \"performance_score\"]\n",
        "\n",
        "plt.scatter(merged[\"total_calibration_time\"], merged[\"performance_score\"])\n",
        "plt.xlabel(\"Total Calibration Time (s)\")\n",
        "plt.ylabel(\"Performance Score\")\n",
        "plt.title(f\"Performance vs Calibration Time (Correlation: {corr_value:.2f})\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lk3HuHPZHoAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nCorrelation with number of calibrations only:\")\n",
        "\n",
        "corr_count = merged[[\"performance_score\", \"count_calibrations\"]].corr(method=\"pearson\")\n",
        "print(corr_count)\n",
        "\n",
        "corr_value_count = corr_count.loc[\"performance_score\", \"count_calibrations\"]\n",
        "plt.scatter(merged[\"count_calibrations\"], merged[\"performance_score\"])\n",
        "plt.xlabel(\"Number of Calibrations\")\n",
        "plt.ylabel(\"Performance Score\")\n",
        "plt.title(f\"Performance vs Number of Calibrations (Correlation: {corr_value_count:.2f})\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1o4HrdEXby_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Survey data summary\n"
      ],
      "metadata": {
        "id": "FFE7FBFGZtUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === Step 1: Upload all survey JSON files ===\n",
        "print(\"Please upload ALL survey_*.json files:\")\n",
        "uploaded_files = files.upload()\n",
        "\n",
        "# === Step 2: Save uploaded files temporarily ===\n",
        "survey_dir = \"uploaded_surveys\"\n",
        "os.makedirs(survey_dir, exist_ok=True)\n",
        "\n",
        "for filename, content in uploaded_files.items():\n",
        "    with open(os.path.join(survey_dir, filename), \"wb\") as f:\n",
        "        f.write(content)\n",
        "\n",
        "# === Step 3: Parse all JSONs and build a summary ===\n",
        "rows = []\n",
        "for file in os.listdir(survey_dir):\n",
        "    if file.endswith(\".json\"):\n",
        "        with open(os.path.join(survey_dir, file), \"r\") as f:\n",
        "            data = json.load(f)\n",
        "        rows.append({\n",
        "            \"user_id\": data.get(\"user_id\"),\n",
        "            \"video_id\": data.get(\"video_id\"),\n",
        "            \"EnjoymentRating\": data.get(\"EnjoymentRating\"),\n",
        "            \"FutureActivityRating\": data.get(\"FutureActivityRating\")\n",
        "        })\n",
        "\n",
        "# === Step 4: Create and sort DataFrame ===\n",
        "df = pd.DataFrame(rows)\n",
        "df.sort_values(by=[\"user_id\", \"video_id\"], inplace=True)\n",
        "print(\"\\nCombined survey table:\\n\")\n",
        "print(df)\n",
        "\n",
        "# === Step 5: Save as CSV and download ===\n",
        "output_file = \"survey_summary.csv\"\n",
        "df.to_csv(output_file, index=False)\n",
        "print(f\"\\nSaved summary as {output_file}\")\n",
        "files.download(output_file)"
      ],
      "metadata": {
        "id": "FeJT5EVPZvjE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Survey and performance correlation analysis"
      ],
      "metadata": {
        "id": "piGOCNePPA01"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge the survey data with the existing merged DataFrame\n",
        "merged_with_survey = merged.merge(df, on=[\"user_id\", \"video_id\"], how=\"left\")\n",
        "\n",
        "# Calculate correlations including survey ratings\n",
        "corrs_with_survey = merged_with_survey[[\"performance_score\", \"EnjoymentRating\", \"FutureActivityRating\"]].corr(method=\"pearson\")\n",
        "\n",
        "print(\"\\nCorrelation matrix between performance and survey ratings:\\n\", corrs_with_survey)\n",
        "\n",
        "# Get the correlation values\n",
        "corr_enjoyment = corrs_with_survey.loc[\"performance_score\", \"EnjoymentRating\"]\n",
        "corr_future_activity = corrs_with_survey.loc[\"performance_score\", \"FutureActivityRating\"]\n",
        "\n",
        "# Add plots for performance vs survey ratings\n",
        "plt.scatter(merged_with_survey[\"EnjoymentRating\"], merged_with_survey[\"performance_score\"])\n",
        "plt.xlabel(\"Enjoyment Rating\")\n",
        "plt.ylabel(\"Performance Score\")\n",
        "plt.title(f\"Performance vs Enjoyment Rating (Correlation: {corr_enjoyment:.2f})\")\n",
        "plt.show()\n",
        "\n",
        "plt.scatter(merged_with_survey[\"FutureActivityRating\"], merged_with_survey[\"performance_score\"])\n",
        "plt.xlabel(\"Future Activity Rating\")\n",
        "plt.ylabel(\"Performance Score\")\n",
        "plt.title(f\"Performance vs Future Activity Rating (Correlation: {corr_future_activity:.2f})\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YTsD8q3nkP6W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}